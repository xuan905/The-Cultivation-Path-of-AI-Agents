"""
model_selector.py
-------------------
åŠŸèƒ½èªªæ˜ï¼š
  æ¯”è¼ƒä¸åŒèªè¨€æ¨¡å‹è¼¸å‡ºæ•ˆæœï¼Œå¹«åŠ©é¸æ“‡æœ€é©åˆçš„æ¨¡å‹ã€‚
  æ˜¯ã€Œé¸åŠŸæ³•ã€çš„ç·´åŠŸå¯¦æˆ°ç¯„ä¾‹ã€‚

ä¿®ä»™æ¯”å–»ï¼š
  é¸åŠŸæ³• â€”â€” ä¸åŒåŠŸæ³•å°æ‡‰ä¸åŒéˆåŠ›å±¬æ€§èˆ‡æ–½å±•æ•ˆæœã€‚
  é€™è£¡æ¯”è¼ƒæ¨¡å‹ï¼Œå°±åƒä¿®å£«é¸æ“‡æœ€é©åˆè‡ªèº«çš„åŠŸæ³•ä¾†ä¿®ç…‰ã€‚
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

# ğŸŒ± æ–½å±•æ³•é™£ï¼Œè¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
OPENAI_API_BASE = os.getenv("OPENAI_API_BASE", "https://api.groq.com/openai/v1")

if not GROQ_API_KEY:
    raise ValueError("âŒ æ²’æœ‰è®€åˆ° GROQ_API_KEYï¼Œè«‹æª¢æŸ¥ .env æˆ–ç’°å¢ƒè®Šæ•¸")

# å¯ä»¥æ¯”è¼ƒçš„æ¨¡å‹æ¸…å–®
models = [
    "llama-3.1-8b-instant",
    "qwen/qwen3-32b",
    "openai/gpt-oss-20b"
]

def compare_models(prompt):
    results = {}
    for model_name in models:
        llm = ChatOpenAI(
            model=model_name,
            temperature=0.7,
            api_key=GROQ_API_KEY,
            base_url=OPENAI_API_BASE
        )
        response = llm.invoke(prompt)
        results[model_name] = response.content
    return results

if __name__ == "__main__":
    print("ğŸ§™ é¸åŠŸæ³•ï¼šæ¯”è¼ƒä¸åŒæ¨¡å‹æ•ˆæœ\n")
    
    prompt = input("ğŸ‘¤ è«‹è¼¸å…¥æƒ³æ¸¬è©¦çš„å•é¡Œæˆ–æè¿°ï¼š")
    results = compare_models(prompt)
    
    for model_name, output in results.items():
        print(f"\nâš” åŠŸæ³•ï¼š{model_name}")
        print("ğŸ§™ éˆæ™ºå›æ‡‰ï¼š", output)
        print("-" * 40)

# ğŸ‘¤ è«‹è¼¸å…¥æƒ³æ¸¬è©¦çš„å•é¡Œæˆ–æè¿°ï¼šä»‹ç´¹ AI Agent


# âš” åŠŸæ³•ï¼šllama-3.1-8b-instant
# ğŸ§™ éˆæ™ºå›æ‡‰ï¼šAI Agent æ˜¯å¯ä»¥è‡ªä¸»åŸ·è¡Œä»»å‹™çš„æ™ºæ…§é«”...

# âš” åŠŸæ³•ï¼šqwen/qwen3-32b
# ğŸ§™ éˆæ™ºå›æ‡‰ï¼šAI Agent å¦‚ä¿®å£«åŠ©æ‰‹ï¼Œèƒ½ç†è§£æŒ‡ä»¤ä¸¦éˆæ´»å®Œæˆä»»å‹™...

# âš” åŠŸæ³•ï¼šopenai/gpt-oss-20b
# ğŸ§™ éˆæ™ºå›æ‡‰ï¼šAI Agent æ˜¯æ™ºæ…§é«”ï¼Œèƒ½æ¥æ”¶æŒ‡ä»¤ã€åˆ†æä»»å‹™ä¸¦æä¾›å›æ‡‰...