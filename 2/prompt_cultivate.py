"""
prompt_cultivate.py
-------------------
åŠŸèƒ½èªªæ˜ï¼š
  å¯¦ä½œ Prompt å·¥ç¨‹ï¼Œè®“ LLM ç”Ÿæˆç‰¹å®šé¢¨æ ¼æ–‡æœ¬ã€‚
  æ˜¯ã€Œéˆæ°£èª¿æ§ã€çš„ç·´åŠŸå¯¦æˆ°ç¯„ä¾‹ã€‚

ä¿®ä»™æ¯”å–»ï¼š
  éˆæ°£èª¿æ§ â€”â€” ä¿®å£«æ“æ§ä¸¹ç”°éˆæ°£ï¼Œæ–½å±•æ³•è¡“ã€‚
  é€™è£¡çš„ Prompt å°±åƒæ–½æ³•æ‰‹å°ï¼Œå¼•å°æ¨¡å‹éˆæ ¹ç™¼æ®ç‰¹å®šèƒ½åŠ›èˆ‡é¢¨æ ¼ã€‚
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

# ğŸŒ± æ–½å±•æ³•é™£ï¼Œè¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# éˆæ ¹ï¼ˆAPI Keyï¼‰ã€åŠŸæ³•ï¼ˆæ¨¡å‹ï¼‰ã€å®—é–€ä¹‹æºï¼ˆBase URLï¼‰
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
LLM_MODEL = os.getenv("LLM_MODEL", "llama-3.1-8b-instant")
OPENAI_API_BASE = os.getenv("OPENAI_API_BASE", "https://api.groq.com/openai/v1")

# ç¢ºèªéˆæ ¹æ˜¯å¦æ³¨å…¥
if not GROQ_API_KEY:
    raise ValueError("âŒ æ²’æœ‰è®€åˆ° GROQ_API_KEYï¼Œè«‹æª¢æŸ¥ .env æˆ–ç’°å¢ƒè®Šæ•¸")

# å¬å–šã€Œéˆæ ¹ã€â€”â€” åˆå§‹åŒ– LLM å®¢æˆ¶ç«¯
llm = ChatOpenAI(
    model=LLM_MODEL,
    temperature=0.7,  # é©åº¦éˆæ°£æ³¢å‹•ï¼Œå¢åŠ æ–‡æœ¬å‰µæ„
    api_key=GROQ_API_KEY,
    base_url=OPENAI_API_BASE
)

def generate_text(prompt, style="ä»™ä¿ "):
    """
    æ ¹æ“š Prompt èˆ‡æŒ‡å®šé¢¨æ ¼ç”Ÿæˆæ–‡æœ¬
    """
    styled_prompt = f"è«‹ç”¨ {style} é¢¨æ ¼å›ç­”ï¼š{prompt}"
    response = llm.invoke(styled_prompt)
    return response.content

if __name__ == "__main__":
    print("ğŸ§™ æ–½å±•éˆæ°£èª¿æ§ï¼Œç·´ç¿’ Prompt å·¥ç¨‹...\n")
    
    while True:
        user_prompt = input("ğŸ‘¤ è¼¸å…¥ä½ çš„å•é¡Œæˆ–æè¿°:ä»‹ç´¹ AI Agentï¼ˆè¼¸å…¥ exit é›¢é–‹ï¼‰ï¼š")
        if user_prompt.lower() == "exit":
            print("ğŸ”š éˆæ°£èª¿æ§çµæŸï¼Œæ³•è¡“æš«æ­‡ã€‚")
            break

        style = input("ğŸ¨ æƒ³è¦çš„é¢¨æ ¼ï¼ˆé è¨­ ä»™ä¿ ï¼‰ï¼š") or "ä»™ä¿ "
        output = generate_text(user_prompt, style)
        print("ğŸ§™ éˆæ™ºå›æ‡‰ï¼š", output)
        print("-" * 40)

# ğŸ’¡ ä¿®ä»™æ¯”å–»ï¼š

# Prompt å°±åƒæ‰‹å°å’Œå’’èªï¼Œæ§åˆ¶éˆæ°£æµå‹•ï¼Œå½±éŸ¿æ³•è¡“æ•ˆæœã€‚

# ä¸åŒé¢¨æ ¼çš„ Prompt å·¥ç¨‹ï¼Œå°±åƒä¸åŒæ³•é–€çš„åŠŸæ³•ï¼Œæœƒè®“æ¨¡å‹çš„ã€Œéˆæ ¹ã€è¡¨ç¾å‡ºä¸åŒçš„èƒ½åŠ›èˆ‡èªæ°£ã€‚