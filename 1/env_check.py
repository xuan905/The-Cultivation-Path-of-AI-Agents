"""
env_check.py
------------
åŠŸèƒ½ï¼šä¿®ä»™ç’°å¢ƒæª¢æŸ¥å’’
  - æª¢æŸ¥éˆæ ¹ï¼ˆAPI Keyï¼‰
  - æª¢æŸ¥åŠŸæ³•ï¼ˆModelï¼‰
  - æª¢æŸ¥å®—é–€ä¹‹æºï¼ˆBase URLï¼‰
  - å˜—è©¦æ‰“é€šéˆè„ˆï¼ˆå‘¼å« LLMï¼‰

æ¯”å–»ï¼š
  ä¿®ä»™å‰è¦å…ˆç¢ºèªå¤©åœ°éˆæ°£æ˜¯å¦å……è¶³ï¼Œå¦å‰‡ä¿®è¡Œå¾’å‹ç„¡åŠŸã€‚
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

def check_env():
    print("ğŸ”® é–‹å§‹æ–½å±•ã€ä¿®ä»™ç’°å¢ƒæª¢æŸ¥å’’ã€‘...\n")

    load_dotenv()

    groq_api_key = os.getenv("GROQ_API_KEY")
    llm_model = os.getenv("LLM_MODEL", "llama-3.1-8b-instant")
    openai_api_base = os.getenv("OPENAI_API_BASE", "https://api.groq.com/openai/v1")

    # éˆæ ¹æª¢æŸ¥
    if groq_api_key:
        print("âœ… éˆæ ¹ï¼ˆGROQ_API_KEYï¼‰å·²æ³¨å…¥ï¼")
    else:
        print("âŒ éˆæ ¹ï¼ˆGROQ_API_KEYï¼‰æœªè¦ºé†’ï¼è«‹æª¢æŸ¥ .env æˆ–ç’°å¢ƒè®Šæ•¸ã€‚")

    # åŠŸæ³•æª¢æŸ¥
    print(f"ğŸ“œ ä½¿ç”¨åŠŸæ³•ï¼ˆLLM_MODELï¼‰ï¼š{llm_model}")

    # å®—é–€ä¹‹æº
    print(f"ğŸ¯ å®—é–€ä¹‹æºï¼ˆOPENAI_API_BASEï¼‰ï¼š{openai_api_base}\n")

    # å˜—è©¦æ‰“é€šéˆè„ˆ
    if groq_api_key:
        try:
            llm = ChatOpenAI(
                model=llm_model,
                temperature=0,
                api_key=groq_api_key,
                base_url=openai_api_base
            )
            resp = llm.invoke("æ­¤åˆ»ï¼Œä½ æ­£è¢«ç”¨ä¾†é©—è­‰ä¿®ä»™ç’°å¢ƒï¼Œè«‹å›è¦†ï¼šã€å¤©åœ°éˆæ°£æµè½‰ï¼Œä¿®ä»™å¯è¡Œï¼ã€")
            print("ğŸ§™ éˆæ™ºå›æ‡‰ï¼š", resp.content)
        except Exception as e:
            print("âš¡ ä¿®ç…‰å¤±æ•—ï¼Œéˆè„ˆå—é˜»ï¼š", e)
    else:
        print("âš ï¸ å› éˆæ ¹æœªæ³¨å…¥ï¼Œç„¡æ³•æ‰“é€šéˆè„ˆã€‚")

if __name__ == "__main__":
    check_env()
