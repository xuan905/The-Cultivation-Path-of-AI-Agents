"""
toolchain_demo.py
-----------------
åŠŸèƒ½èªªæ˜ï¼š
  ç¤ºç¯„ AI Agent å·¥å…·éˆè¨­è¨ˆï¼ˆä¸²æ¥å¤šå€‹å·¥å…·å½¢æˆ pipelineï¼‰ã€‚
  æ¯å€‹å·¥å…·åƒæ³•å¯¶ï¼Œä¸²æ¥å¾Œå½¢æˆå®Œæ•´é™£æ³•ã€‚

ä¿®ä»™æ¯”å–»ï¼š
  - æ¯å€‹å·¥å…· = æ³•å¯¶
  - ä¸²æ¥å·¥å…· = å¸ƒç½®å°é€±å¤©ï¼ŒéˆåŠ›å¾ªç’°
  - Agent åŸ·è¡Œä»»å‹™ = æ³•è¡“é€£ç’°é‡‹æ”¾

æ¸¬è©¦ç¯„ä¾‹

è¼¸å…¥ï¼š

è«‹å¹«æˆ‘è¨ˆç®— 23*19ï¼Œä¸¦å‘Šè¨´æˆ‘å°åŒ—çš„å¤©æ°£


å¯èƒ½å›è¦†ï¼š

âœ¨ å·¥å…·éˆå›æ‡‰ï¼š
ğŸ§® è¨ˆç®—çµæœï¼š23*19 = 437
ğŸŒ ç¿»è­¯å¾Œï¼š23*19 = 437
ğŸŒ¤ å¤©æ°£è³‡è¨Šï¼ˆå°åŒ—ï¼‰ï¼š{'temperature': 29.1, 'windspeed': 3.4, ...}
é€™å°±åƒå°é€±å¤©é‹è½‰ï¼Œè¨ˆç®—ã€ç¿»è­¯ã€æŸ¥å¤©æ°£ä¸‰å€‹æ³•å¯¶ä¾åºé‹ä½œï¼Œæœ€çµ‚å®Œæˆä»»å‹™ã€‚
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
import sympy as sp
from deep_translator import GoogleTranslator
import requests
import re

# ğŸŒ± è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
LLM_MODEL = os.getenv("LLM_MODEL", "llama-3.1-8b-instant")
OPENAI_API_BASE = os.getenv("OPENAI_API_BASE", "https://api.groq.com/openai/v1")

if not GROQ_API_KEY:
    raise ValueError("âŒ æ²’æœ‰è®€åˆ° GROQ_API_KEYï¼Œè«‹æª¢æŸ¥ .env æˆ–ç’°å¢ƒè®Šæ•¸")

# ğŸ§™ åˆå§‹åŒ– LLM
llm = ChatOpenAI(
    model=LLM_MODEL,
    temperature=0.7,
    api_key=GROQ_API_KEY,
    base_url=OPENAI_API_BASE,
)

# ğŸ”® å·¥å…· 1ï¼šè¨ˆç®—å™¨
def calculator(expression: str):
    try:
        result = sp.sympify(expression).evalf()
        return f"{expression} = {result}"
    except Exception as e:
        return f"âŒ è¨ˆç®—å¤±æ•—ï¼š{e}"

# ğŸ”® å·¥å…· 2ï¼šç¿»è­¯å™¨ï¼ˆè‹±æ–‡ â†’ ä¸­æ–‡ï¼‰
def translate_to_chinese(text: str):
    try:
        translated = GoogleTranslator(source="en", target="zh-TW").translate(text)
        return translated
    except Exception as e:
        return f"âŒ ç¿»è­¯å¤±æ•—ï¼š{e}"

# ğŸ”® å·¥å…· 3ï¼šå¤©æ°£æŸ¥è©¢
def get_weather(latitude: float, longitude: float):
    url = f"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true"
    response = requests.get(url)
    data = response.json()
    return data["current_weather"]

# ğŸ”® è¼”åŠ©ï¼šæŠ½å–æ•¸å­¸è¡¨é”å¼
def extract_expression(text: str):
    match = re.search(r'(\d+(\s*[\+\-\*/]\s*\d+)+)', text)
    if match:
        return match.group(1).replace(" ", "")
    return None

# ğŸ§™ Agent å·¥å…·éˆ
def toolchain_agent(task: str):
    """
    åˆ¤æ–·ä»»å‹™ï¼Œä¸²æ¥è¨ˆç®—ã€ç¿»è­¯ã€å¤©æ°£ç­‰å·¥å…·ï¼Œç”Ÿæˆå®Œæ•´å›æ‡‰ã€‚
    """
    # 1ï¸âƒ£ åˆ¤æ–·æ˜¯å¦åŒ…å«æ•¸å­¸é‹ç®—
    calc_prompt = f"è«‹å¾ä»»å‹™ä¸­æ‰¾å‡ºæ•¸å­¸é‹ç®—å¼ï¼š{task}ï¼Œå¦‚æœæ²’æœ‰ï¼Œå›è¦† 'ç„¡'"
    response = llm.invoke(calc_prompt)
    expr = extract_expression(response.content.strip())

    result_parts = []

    if expr:
        calc_result = calculator(expr)
        result_parts.append(f"ğŸ§® è¨ˆç®—çµæœï¼š{calc_result}")
        translated = translate_to_chinese(calc_result)
        result_parts.append(f"ğŸŒ ç¿»è­¯å¾Œï¼š{translated}")

    # 2ï¸âƒ£ åˆ¤æ–·æ˜¯å¦éœ€è¦å¤©æ°£è³‡è¨Š
    weather_prompt = f"è«‹åˆ¤æ–·ä»»å‹™ä¸­æ˜¯å¦éœ€è¦æŸ¥å¤©æ°£ï¼Œå›è¦†éœ€è¦æˆ–ç„¡éœ€ï¼š{task}"
    weather_resp = llm.invoke(weather_prompt).content.strip().lower()
    if "éœ€" in weather_resp:
        # ç¯„ä¾‹åº§æ¨™
        coords = {"å°åŒ—": (25.0330, 121.5654), "æ±äº¬": (35.6895, 139.6917)}
        loc = "å°åŒ—"  # é è¨­
        if any(city in task for city in coords):
            loc = [city for city in coords if city in task][0]
        lat, lon = coords[loc]
        weather = get_weather(lat, lon)
        result_parts.append(f"ğŸŒ¤ å¤©æ°£è³‡è¨Šï¼ˆ{loc}ï¼‰ï¼š{weather}")

    if not result_parts:
        return "ä»»å‹™ä¸éœ€è¦å·¥å…·éˆæ“ä½œã€‚"

    return "\n".join(result_parts)


if __name__ == "__main__":
    print("ğŸ§™ å•Ÿå‹•å·¥å…·éˆæ¼”ç¤º Â· å°é€±å¤©é‹è½‰...\n")

    while True:
        task = input("ğŸ‘¤ è¼¸å…¥ä»»å‹™ï¼ˆè¼¸å…¥ exit é›¢é–‹ï¼‰ï¼š")
        if task.lower() == "exit":
            print("ğŸ”š å·¥å…·éˆæ”¶èµ·ï¼Œé™£æ³•æš«æ­¢ã€‚")
            break

        output = toolchain_agent(task)
        print("âœ¨ å·¥å…·éˆå›æ‡‰ï¼š\n", output)
        print("-" * 40)
